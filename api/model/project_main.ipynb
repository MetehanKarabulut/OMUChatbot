{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Çekme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "temp= list(map(lambda x : x.split('~'),list(map(lambda x:x.replace('\\n',''),data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soru-Cevap çiftlerinin ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(map(lambda x : x[0], temp))\n",
    "answers = list(map(lambda x : x[1], temp))\n",
    "del(temp, file, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri temizliği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stopwords = None\n",
    "\n",
    "with open(\"turkce-stop-words.txt\", \"r\", encoding='utf-8') as file:\n",
    "    turkish_stopwords = set(file.read().replace(\"\\n\",\" \").split())\n",
    "\n",
    "import re\n",
    "\n",
    "def veri_temizligi(text):\n",
    "    metin = re.sub(\"[^a-zA-ZçÇğĞıİöÖşŞüÜ]\", \" \", text).lower()\n",
    "    kelimeler = metin.split()\n",
    "    kelimeler = [i for i in kelimeler if not i in turkish_stopwords]\n",
    "    \n",
    "    return kelimeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin filtrelenip güncellenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(data):\n",
    "    MAX_LEN = 0\n",
    "    for i in range(len(data)):\n",
    "        kokler = veri_temizligi(data[i])\n",
    "        MAX_LEN = len(kokler) if MAX_LEN < len(kokler) else MAX_LEN  \n",
    "        data[i] = \" \".join(kokler)\n",
    "        \n",
    "    return data, MAX_LEN\n",
    "\n",
    "questions_data , MAX_LEN_QUESTION = update_dataset(questions)\n",
    "answers_data , MAX_LEN_ANSWER = update_dataset(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(MAX_LEN_ANSWER, MAX_LEN_QUESTION)\n",
    "del(MAX_LEN_QUESTION, MAX_LEN_ANSWER, answers, questions, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelime sözlüğü oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "temp_list = answers_data + questions_data\n",
    "word_num = 0\n",
    "\n",
    "for line in temp_list:\n",
    "    for i in line.split():\n",
    "        if not i in vocab:\n",
    "            vocab[i] = word_num\n",
    "            word_num += 1\n",
    "\n",
    "for i in range(len(answers_data)):\n",
    "    answers_data[i] = '<SOS> ' + answers_data[i] + ' <EOS>'\n",
    "\n",
    "del(i, line, word_num, temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cümlelere özel tokenların eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "length_of_vocab = len(vocab)\n",
    "\n",
    "for token in tokens:\n",
    "    vocab[token] = length_of_vocab\n",
    "    length_of_vocab += 1\n",
    "\n",
    "vocab[list(vocab.items())[0][0]] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "inv_vocab = {k:v for v,k in vocab.items()}\n",
    "del(length_of_vocab, token, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenler için decoder-encoder oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_encoder(input):\n",
    "    main_list = []\n",
    "    for line in input:\n",
    "        temp_list = []\n",
    "        for word in line.split():\n",
    "            temp_list.append(vocab['<OUT>'] if word not in vocab else vocab[word])\n",
    "\n",
    "        main_list.append(temp_list)\n",
    "    return main_list\n",
    "\n",
    "encoder_input = decoder_encoder(questions_data)\n",
    "decoder_input = decoder_encoder(answers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilen kelime matrisine çevrilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = pad_sequences(list(map(lambda x:x[1:],decoder_input)), MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM katmanı oluşturulması\n",
    "#### LSTM'e verilen nöron sayısı 128e çekildi. 64e çekilebilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 13:14:52.499598: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-06-22 13:14:52.499621: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-22 13:14:52.499627: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-22 13:14:52.500022: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-22 13:14:52.500429: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 13:14:54.591716: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:14:55.031817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:14:55.520143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:14:57.366902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:14:57.876365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 7s 58ms/step - loss: 3.6651 - accuracy: 0.5356\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 2.4966 - accuracy: 0.6150\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.2151 - accuracy: 0.6254\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.9455 - accuracy: 0.6523\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.6715 - accuracy: 0.6873\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.4005 - accuracy: 0.7284\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.1795 - accuracy: 0.7621\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.0204 - accuracy: 0.7882\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.8939 - accuracy: 0.8085\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.8099 - accuracy: 0.8229\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.7491 - accuracy: 0.8369\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6951 - accuracy: 0.8464\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6623 - accuracy: 0.8516\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6334 - accuracy: 0.8576\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.8601\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5930 - accuracy: 0.8632\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5856 - accuracy: 0.8644\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5824 - accuracy: 0.8656\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5763 - accuracy: 0.8668\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5786 - accuracy: 0.8642\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5690 - accuracy: 0.8656\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5705 - accuracy: 0.8657\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5631 - accuracy: 0.8667\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5600 - accuracy: 0.8662\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5628 - accuracy: 0.8651\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5546 - accuracy: 0.8668\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5500 - accuracy: 0.8679\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5416 - accuracy: 0.8679\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5425 - accuracy: 0.8667\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5474 - accuracy: 0.8673\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5353 - accuracy: 0.8691\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5255 - accuracy: 0.8714\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5172 - accuracy: 0.8716\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5149 - accuracy: 0.8724\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5112 - accuracy: 0.8740\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5055 - accuracy: 0.8733\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5086 - accuracy: 0.8743\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5120 - accuracy: 0.8736\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5201 - accuracy: 0.8720\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5151 - accuracy: 0.8708\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6025 - accuracy: 0.8605\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5859 - accuracy: 0.8576\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5439 - accuracy: 0.8673\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4953 - accuracy: 0.8741\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4732 - accuracy: 0.8794\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4455 - accuracy: 0.8826\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4225 - accuracy: 0.8869\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4025 - accuracy: 0.8915\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3747 - accuracy: 0.8971\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3722 - accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x173f76c40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "enc_inp = Input(shape=(MAX_LEN,))\n",
    "dec_inp = Input(shape=(MAX_LEN,))\n",
    "\n",
    "embed = Embedding(len(vocab) + 1, output_dim=50, input_length=MAX_LEN, trainable=True)\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h,c]\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(len(vocab), activation='softmax')\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0125)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "model.fit([encoder_input, decoder_input], decoder_final_output, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "dec_model = Model([dec_inp] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 13:16:03.331082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:16:03.509845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 284ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 13:16:04.454298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-22 13:16:04.559495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "chatbot attention : Atakum \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "chatbot attention : Evet Çeşitli Birimlerde Part Time Çalışma Imkanı Bulunmaktadır \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "chatbot attention : Anemon Samsun Hotel \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "prepro1 = \"\"\n",
    "sayac = 0\n",
    "while sayac < 3:\n",
    "    sayac += 1\n",
    "    prepro1 = input(\"you : \")\n",
    "    prepro1 = ' '.join(veri_temizligi(prepro1))\n",
    "    prepro = [prepro1]\n",
    "\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        \n",
    "        txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, MAX_LEN, padding='post', truncating=\"post\")\n",
    "\n",
    "    stat = enc_model.predict(txt)\n",
    "    empty_target_seq = np.zeros((1,1))\n",
    "    empty_target_seq[0,0] = vocab['<SOS>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat)\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sample_word_index = np.argmax(decoder_concat_input[0, -1, :])\n",
    "        sample_word = inv_vocab[sample_word_index] + ' '\n",
    "        \n",
    "        if sample_word != '<EOS> ':\n",
    "            decoded_translation += sample_word\n",
    "\n",
    "        if sample_word == '<EOS> ' or len(decoded_translation.split()) > MAX_LEN:\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0,0] = sample_word_index\n",
    "        stat = [h, c]\n",
    "        \n",
    "    print(f'chatbot attention : {decoded_translation.title()}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
