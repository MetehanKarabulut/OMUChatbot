{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Çekme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "temp= list(map(lambda x : x.split('~'),list(map(lambda x:x.replace('\\n',''),data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soru-Cevap çiftlerinin ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(map(lambda x : x[0], temp))\n",
    "answers = list(map(lambda x : x[1], temp))\n",
    "del(temp, file, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri temizliği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stopwords = None\n",
    "\n",
    "with open(\"turkce-stop-words.txt\", \"r\", encoding='utf-8') as file:\n",
    "    turkish_stopwords = set(file.read().replace(\"\\n\",\" \").split())\n",
    "\n",
    "import re\n",
    "\n",
    "def veri_temizligi(text):\n",
    "    metin = re.sub(\"[^a-zA-ZçÇğĞıİöÖşŞüÜ]\", \" \", text).lower()\n",
    "    kelimeler = metin.split()\n",
    "    kelimeler = [i for i in kelimeler if not i in turkish_stopwords]\n",
    "    \n",
    "    return kelimeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin filtrelenip güncellenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(data):\n",
    "    MAX_LEN = 0\n",
    "    for i in range(len(data)):\n",
    "        kokler = veri_temizligi(data[i])\n",
    "        MAX_LEN = len(kokler) if MAX_LEN < len(kokler) else MAX_LEN  \n",
    "        data[i] = \" \".join(kokler)\n",
    "        \n",
    "    return data, MAX_LEN\n",
    "\n",
    "questions_data , MAX_LEN_QUESTION = update_dataset(questions)\n",
    "answers_data , MAX_LEN_ANSWER = update_dataset(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(MAX_LEN_ANSWER, MAX_LEN_QUESTION)\n",
    "del(MAX_LEN_QUESTION, MAX_LEN_ANSWER, answers, questions, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelime sözlüğü oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "temp_list = answers_data + questions_data\n",
    "word_num = 0\n",
    "\n",
    "for line in temp_list:\n",
    "    for i in line.split():\n",
    "        if not i in vocab:\n",
    "            vocab[i] = word_num\n",
    "            word_num += 1\n",
    "\n",
    "for i in range(len(answers_data)):\n",
    "    answers_data[i] = '<SOS> ' + answers_data[i] + ' <EOS>'\n",
    "\n",
    "del(i, line, word_num, temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cümlelere özel tokenların eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "length_of_vocab = len(vocab)\n",
    "\n",
    "for token in tokens:\n",
    "    vocab[token] = length_of_vocab\n",
    "    length_of_vocab += 1\n",
    "\n",
    "vocab[list(vocab.items())[0][0]] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "inv_vocab = {k:v for v,k in vocab.items()}\n",
    "del(length_of_vocab, token, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenler için decoder-encoder oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_encoder(input):\n",
    "    main_list = []\n",
    "    for line in input:\n",
    "        temp_list = []\n",
    "        for word in line.split():\n",
    "            temp_list.append(vocab['<OUT>'] if word not in vocab else vocab[word])\n",
    "\n",
    "        main_list.append(temp_list)\n",
    "    return main_list\n",
    "\n",
    "encoder_input = decoder_encoder(questions_data)\n",
    "decoder_input = decoder_encoder(answers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilen kelime matrisine çevrilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = pad_sequences(list(map(lambda x:x[1:],decoder_input)), MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM katmanı oluşturulması\n",
    "#### LSTM'e verilen nöron sayısı 128e çekildi. 64e çekilebilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 22:04:09.505309: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-06-23 22:04:09.505335: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-23 22:04:09.505342: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-23 22:04:09.505609: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-23 22:04:09.505627: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 22:04:11.140345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-23 22:04:11.391197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-23 22:04:11.453331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-23 22:04:11.597669: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-23 22:04:11.703405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 27ms/step - loss: 3.4807 - accuracy: 0.5498\n",
      "Epoch 2/60\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4309 - accuracy: 0.6249\n",
      "Epoch 3/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.1739 - accuracy: 0.6321\n",
      "Epoch 4/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9343 - accuracy: 0.6566\n",
      "Epoch 5/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.6505 - accuracy: 0.6961\n",
      "Epoch 6/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.3912 - accuracy: 0.7300\n",
      "Epoch 7/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.1663 - accuracy: 0.7672\n",
      "Epoch 8/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 1.0213 - accuracy: 0.7893\n",
      "Epoch 9/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.8873 - accuracy: 0.8129\n",
      "Epoch 10/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7808 - accuracy: 0.8333\n",
      "Epoch 11/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.7186 - accuracy: 0.8449\n",
      "Epoch 12/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7424 - accuracy: 0.8415\n",
      "Epoch 13/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6715 - accuracy: 0.8555\n",
      "Epoch 14/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6139 - accuracy: 0.8641\n",
      "Epoch 15/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5796 - accuracy: 0.8700\n",
      "Epoch 16/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5535 - accuracy: 0.8714\n",
      "Epoch 17/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5280 - accuracy: 0.8746\n",
      "Epoch 18/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5115 - accuracy: 0.8758\n",
      "Epoch 19/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4798 - accuracy: 0.8814\n",
      "Epoch 20/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4601 - accuracy: 0.8856\n",
      "Epoch 21/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4521 - accuracy: 0.8839\n",
      "Epoch 22/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4255 - accuracy: 0.8887\n",
      "Epoch 23/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4172 - accuracy: 0.8892\n",
      "Epoch 24/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3931 - accuracy: 0.8971\n",
      "Epoch 25/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3705 - accuracy: 0.9003\n",
      "Epoch 26/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3501 - accuracy: 0.9057\n",
      "Epoch 27/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3421 - accuracy: 0.9057\n",
      "Epoch 28/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3403 - accuracy: 0.9078\n",
      "Epoch 29/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3193 - accuracy: 0.9103\n",
      "Epoch 30/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3027 - accuracy: 0.9147\n",
      "Epoch 31/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2874 - accuracy: 0.9178\n",
      "Epoch 32/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2674 - accuracy: 0.9224\n",
      "Epoch 33/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2557 - accuracy: 0.9257\n",
      "Epoch 34/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2536 - accuracy: 0.9253\n",
      "Epoch 35/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2455 - accuracy: 0.9273\n",
      "Epoch 36/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2481 - accuracy: 0.9272\n",
      "Epoch 37/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2296 - accuracy: 0.9319\n",
      "Epoch 38/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.2149 - accuracy: 0.9353\n",
      "Epoch 39/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1977 - accuracy: 0.9392\n",
      "Epoch 40/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1898 - accuracy: 0.9415\n",
      "Epoch 41/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1872 - accuracy: 0.9424\n",
      "Epoch 42/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1782 - accuracy: 0.9457\n",
      "Epoch 43/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1771 - accuracy: 0.9448\n",
      "Epoch 44/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1711 - accuracy: 0.9480\n",
      "Epoch 45/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1508 - accuracy: 0.9539\n",
      "Epoch 46/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1421 - accuracy: 0.9555\n",
      "Epoch 47/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1215 - accuracy: 0.9619\n",
      "Epoch 48/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1146 - accuracy: 0.9652\n",
      "Epoch 49/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.1145 - accuracy: 0.9635\n",
      "Epoch 50/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1067 - accuracy: 0.9659\n",
      "Epoch 51/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.1040 - accuracy: 0.9687\n",
      "Epoch 52/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0990 - accuracy: 0.9705\n",
      "Epoch 53/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0929 - accuracy: 0.9719\n",
      "Epoch 54/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0882 - accuracy: 0.9724\n",
      "Epoch 55/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.0945 - accuracy: 0.9702\n",
      "Epoch 56/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0940 - accuracy: 0.9719\n",
      "Epoch 57/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0924 - accuracy: 0.9713\n",
      "Epoch 58/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0865 - accuracy: 0.9727\n",
      "Epoch 59/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0836 - accuracy: 0.9750\n",
      "Epoch 60/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.0716 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x30da72c40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "enc_inp = Input(shape=(MAX_LEN,))\n",
    "dec_inp = Input(shape=(MAX_LEN,))\n",
    "\n",
    "embed = Embedding(len(vocab) + 1, output_dim=50, input_length=MAX_LEN, trainable=True)\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h,c]\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(len(vocab), activation='softmax')\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0125)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "model.fit([encoder_input, decoder_input], decoder_final_output, epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "dec_model = Model([dec_inp] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: Öğrencilerin en çok katıldığı teknik geziler hangi bölümde düzenlenir?\n",
      "Chatbot: Jeoloji Mühendisliği Bölümü \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: en çok öğrencinin katıldığı teknik gezi hangi bölümde düzenlenir\n",
      "Chatbot: Jeoloji Mühendisliği Bölümü \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: \n",
      "Chatbot: Yaşındayım Yaşındasın \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "prepro1 = \"\"\n",
    "sayac = 0\n",
    "while sayac < 3:\n",
    "    sayac += 1\n",
    "    prepro1 = input(\"you : \")\n",
    "    soru = prepro1\n",
    "    prepro1 = ' '.join(veri_temizligi(prepro1))\n",
    "    prepro = [prepro1]\n",
    "\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        \n",
    "        txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, MAX_LEN, padding='post', truncating=\"post\")\n",
    "\n",
    "    stat = enc_model.predict(txt)\n",
    "    empty_target_seq = np.zeros((1,1))\n",
    "    empty_target_seq[0,0] = vocab['<SOS>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat)\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sample_word_index = np.argmax(decoder_concat_input[0, -1, :])\n",
    "        sample_word = inv_vocab[sample_word_index] + ' '\n",
    "        \n",
    "        if sample_word != '<EOS> ':\n",
    "            decoded_translation += sample_word\n",
    "\n",
    "        if sample_word == '<EOS> ' or len(decoded_translation.split()) > MAX_LEN:\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0,0] = sample_word_index\n",
    "        stat = [h, c]\n",
    "        \n",
    "    print(f'Sen: {soru}')    \n",
    "    print(f'Chatbot: {decoded_translation.title()}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
