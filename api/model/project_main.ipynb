{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Çekme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "temp= list(map(lambda x : x.split('~'),list(map(lambda x:x.replace('\\n',''),data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soru-Cevap çiftlerinin ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(map(lambda x : x[0], temp))\n",
    "answers = list(map(lambda x : x[1], temp))\n",
    "del(temp, file, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri temizliği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_stopwords = None\n",
    "\n",
    "with open(\"turkce-stop-words.txt\", \"r\", encoding='utf-8') as file:\n",
    "    turkish_stopwords = set(file.read().replace(\"\\n\",\" \").split())\n",
    "\n",
    "import re\n",
    "\n",
    "def veri_temizligi(text):\n",
    "    metin = re.sub(\"[^a-zA-ZçÇğĞıİöÖşŞüÜ]\", \" \", text).lower()\n",
    "    kelimeler = metin.split()\n",
    "    kelimeler = [i for i in kelimeler if not i in turkish_stopwords]\n",
    "    \n",
    "    return kelimeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilerin filtrelenip güncellenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(data):\n",
    "    MAX_LEN = 0\n",
    "    for i in range(len(data)):\n",
    "        kokler = veri_temizligi(data[i])\n",
    "        MAX_LEN = len(kokler) if MAX_LEN < len(kokler) else MAX_LEN  \n",
    "        data[i] = \" \".join(kokler)\n",
    "        \n",
    "    return data, MAX_LEN\n",
    "\n",
    "questions_data , MAX_LEN_QUESTION = update_dataset(questions)\n",
    "answers_data , MAX_LEN_ANSWER = update_dataset(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max(MAX_LEN_ANSWER, MAX_LEN_QUESTION)\n",
    "del(MAX_LEN_QUESTION, MAX_LEN_ANSWER, answers, questions, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelime sözlüğü oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "temp_list = answers_data + questions_data\n",
    "word_num = 0\n",
    "\n",
    "for line in temp_list:\n",
    "    for i in line.split():\n",
    "        if not i in vocab:\n",
    "            vocab[i] = word_num\n",
    "            word_num += 1\n",
    "\n",
    "for i in range(len(answers_data)):\n",
    "    answers_data[i] = '<SOS> ' + answers_data[i] + ' <EOS>'\n",
    "\n",
    "del(i, line, word_num, temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cümlelere özel tokenların eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "length_of_vocab = len(vocab)\n",
    "\n",
    "for token in tokens:\n",
    "    vocab[token] = length_of_vocab\n",
    "    length_of_vocab += 1\n",
    "\n",
    "vocab[list(vocab.items())[0][0]] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "inv_vocab = {k:v for v,k in vocab.items()}\n",
    "del(length_of_vocab, token, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenler için decoder-encoder oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_encoder(input):\n",
    "    main_list = []\n",
    "    for line in input:\n",
    "        temp_list = []\n",
    "        for word in line.split():\n",
    "            temp_list.append(vocab['<OUT>'] if word not in vocab else vocab[word])\n",
    "\n",
    "        main_list.append(temp_list)\n",
    "    return main_list\n",
    "\n",
    "encoder_input = decoder_encoder(questions_data)\n",
    "decoder_input = decoder_encoder(answers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verilen kelime matrisine çevrilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = pad_sequences(list(map(lambda x:x[1:],decoder_input)), MAX_LEN, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM katmanı oluşturulması\n",
    "#### LSTM'e verilen nöron sayısı 128e çekildi. 64e çekilebilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:50:31.211173: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-06-30 18:50:31.211196: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-30 18:50:31.211202: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-30 18:50:31.211551: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-30 18:50:31.212037: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:50:32.948482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:50:33.194981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:50:33.266913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:50:33.405926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:50:33.511792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 28ms/step - loss: 3.6749 - accuracy: 0.5313\n",
      "Epoch 2/60\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 2.4531 - accuracy: 0.6221\n",
      "Epoch 3/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 2.1647 - accuracy: 0.6337\n",
      "Epoch 4/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.9149 - accuracy: 0.6583\n",
      "Epoch 5/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 1.6843 - accuracy: 0.6887\n",
      "Epoch 6/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.4298 - accuracy: 0.7270\n",
      "Epoch 7/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.2170 - accuracy: 0.7582\n",
      "Epoch 8/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 1.0407 - accuracy: 0.7855\n",
      "Epoch 9/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.9071 - accuracy: 0.8100\n",
      "Epoch 10/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7978 - accuracy: 0.8296\n",
      "Epoch 11/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7231 - accuracy: 0.8453\n",
      "Epoch 12/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6743 - accuracy: 0.8534\n",
      "Epoch 13/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6470 - accuracy: 0.8623\n",
      "Epoch 14/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6278 - accuracy: 0.8611\n",
      "Epoch 15/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6093 - accuracy: 0.8649\n",
      "Epoch 16/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6045 - accuracy: 0.8655\n",
      "Epoch 17/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5950 - accuracy: 0.8653\n",
      "Epoch 18/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6095 - accuracy: 0.8642\n",
      "Epoch 19/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6262 - accuracy: 0.8594\n",
      "Epoch 20/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5769 - accuracy: 0.8672\n",
      "Epoch 21/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5568 - accuracy: 0.8718\n",
      "Epoch 22/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5456 - accuracy: 0.8729\n",
      "Epoch 23/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5377 - accuracy: 0.8731\n",
      "Epoch 24/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5330 - accuracy: 0.8750\n",
      "Epoch 25/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.5208 - accuracy: 0.8767\n",
      "Epoch 26/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5239 - accuracy: 0.8757\n",
      "Epoch 27/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5275 - accuracy: 0.8737\n",
      "Epoch 28/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5075 - accuracy: 0.8778\n",
      "Epoch 29/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5014 - accuracy: 0.8781\n",
      "Epoch 30/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4849 - accuracy: 0.8815\n",
      "Epoch 31/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4899 - accuracy: 0.8813\n",
      "Epoch 32/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.5021 - accuracy: 0.8773\n",
      "Epoch 33/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.4871 - accuracy: 0.8799\n",
      "Epoch 34/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4703 - accuracy: 0.8830\n",
      "Epoch 35/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4503 - accuracy: 0.8852\n",
      "Epoch 36/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4402 - accuracy: 0.8893\n",
      "Epoch 37/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4309 - accuracy: 0.8897\n",
      "Epoch 38/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.4122 - accuracy: 0.8934\n",
      "Epoch 39/60\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.3952 - accuracy: 0.8979\n",
      "Epoch 40/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3882 - accuracy: 0.8986\n",
      "Epoch 41/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3745 - accuracy: 0.9000\n",
      "Epoch 42/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3598 - accuracy: 0.9037\n",
      "Epoch 43/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3437 - accuracy: 0.9076\n",
      "Epoch 44/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3310 - accuracy: 0.9110\n",
      "Epoch 45/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3351 - accuracy: 0.9095\n",
      "Epoch 46/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3356 - accuracy: 0.9097\n",
      "Epoch 47/60\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.3239 - accuracy: 0.9127\n",
      "Epoch 48/60\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.3209 - accuracy: 0.9146\n",
      "Epoch 49/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.3200 - accuracy: 0.9130\n",
      "Epoch 50/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.3285 - accuracy: 0.9144\n",
      "Epoch 51/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3322 - accuracy: 0.9112\n",
      "Epoch 52/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3137 - accuracy: 0.9141\n",
      "Epoch 53/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.3075 - accuracy: 0.9170\n",
      "Epoch 54/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.3016 - accuracy: 0.9157\n",
      "Epoch 55/60\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.2856 - accuracy: 0.9209\n",
      "Epoch 56/60\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.2676 - accuracy: 0.9245\n",
      "Epoch 57/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2510 - accuracy: 0.9305\n",
      "Epoch 58/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2492 - accuracy: 0.9312\n",
      "Epoch 59/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2370 - accuracy: 0.9328\n",
      "Epoch 60/60\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.2348 - accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x301b378e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "enc_inp = Input(shape=(MAX_LEN,))\n",
    "dec_inp = Input(shape=(MAX_LEN,))\n",
    "\n",
    "embed = Embedding(len(vocab) + 1, output_dim=50, input_length=MAX_LEN, trainable=True)\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h,c]\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(len(vocab), activation='softmax')\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0125)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "model.fit([encoder_input, decoder_input], decoder_final_output, epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "dec_model = Model([dec_inp] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:51:34.793447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:51:34.844266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 18:51:35.015053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-06-30 18:51:35.055097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: merhaba nasılsın\n",
      "Chatbot: Merhaba Iyiyim Nasılsın \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: \n",
      "Chatbot: Atatürk Parkı Batıpark Açık Hava Konser Alanlarıdır \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Sen: \n",
      "Chatbot: Atatürk Parkı Batıpark Açık Hava Konser Alanlarıdır \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "prepro1 = \"\"\n",
    "sayac = 0\n",
    "while sayac < 3:\n",
    "    sayac += 1\n",
    "    prepro1 = input(\"you : \")\n",
    "    soru = prepro1\n",
    "    prepro1 = ' '.join(veri_temizligi(prepro1))\n",
    "    prepro = [prepro1]\n",
    "\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        \n",
    "        txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, MAX_LEN, padding='post', truncating=\"post\")\n",
    "\n",
    "    stat = enc_model.predict(txt)\n",
    "    empty_target_seq = np.zeros((1,1))\n",
    "    empty_target_seq[0,0] = vocab['<SOS>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat)\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sample_word_index = np.argmax(decoder_concat_input[0, -1, :])\n",
    "        sample_word = inv_vocab[sample_word_index] + ' '\n",
    "        \n",
    "        if sample_word != '<EOS> ':\n",
    "            decoded_translation += sample_word\n",
    "\n",
    "        if sample_word == '<EOS> ' or len(decoded_translation.split()) > MAX_LEN:\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0,0] = sample_word_index\n",
    "        stat = [h, c]\n",
    "        \n",
    "    print(f'Sen: {soru}')    \n",
    "    print(f'Chatbot: {decoded_translation.title()}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
